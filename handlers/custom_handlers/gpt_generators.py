import asyncio
from aiogram.types import Message, User
from aiogram import Router, F
from aiogram.fsm.context import FSMContext
from typing import Optional

from api.gpt_generators import gpt_text  # , gpt_image
from states import main_states as st
from database.requests import put_txt_gpt_data_to_db
import config_data.config as config
from utils.actions_decorators import typing_action
from utils.loguru_logger import log  # –ò–º–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞

router = Router()


@router.message(F.text == "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å \n—Ç–µ–∫—Å—Ç üìÑ")
@typing_action(delay=1)
async def cmd_generate_text(message: Message, state: FSMContext) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É –¥–ª—è –Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.

    :param message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    :param state: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è FSM.
    """
    try:
        log.debug("The user started generating text")
        await state.set_state(st.MainStates.await_input_for_gen_text)
        await message.answer('–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å')
        user_id = message.from_user.id if message.from_user else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'
        log.info(f"User {user_id} set the state {st.MainStates.await_input_for_gen_text}")
        # log.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {message.from_user.id} —É—Å—Ç–∞–Ω–æ–≤–∏–ª —Å–æ—Å—Ç–æ—è–Ω–∏–µ {st.MainStates.await_input_for_gen_text}")

    except Exception as err:
        log.error(f"Error setting state for text generation: {repr(err)}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


@router.message(st.MainStates.await_input_for_gen_text)
@typing_action(delay=1)
async def send_result(message: Message, state: FSMContext) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

    :param message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    :param state: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è FSM.
    """
    user: Optional[User] = message.from_user
    if not user:
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        log.error("Failed to determine user.")
        return
    
    log.debug("Processing user input to generate text")
    await state.set_state(st.MainStates.processing_state)
    log.info(f"Request to generate text from {user.username}: {message.text}")
    
    await message.answer(config.WAIT_MESSAGE_AFTER_COMMAND + config.WAIT_MESSAGE_AFTER_COMMAND_TXT)
    if message.text is None:
        await message.answer("–ó–∞–ø—Ä–æ—Å –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        await state.clear()
        return
    
    response = await gpt_text(message.text)
    if not response or not response.choices or not response.choices[0].message:
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç GPT.")
        await state.clear()
        return
    
    if response.choices[0].message.content and response.usage:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        model_name = response.model
        log.debug(f"Model {model_name} used {response.usage.total_tokens} tokens for response.")
    
        await put_txt_gpt_data_to_db(request=message.text,
                                     answer=response.choices[0].message.content,
                                     total_token_quantity=response.usage.total_tokens,
                                     model_name=model_name,
                                     user_id=user.id,
                                     )
    if response.usage:
        log.info(f"Data is saved in the database for the user {user.id}")
        log.debug(f"Costs per request (in tokens): \n"
                  f"Prompt tokens: {response.usage.prompt_tokens}, \n"
                  f"Completion tokens: {response.usage.completion_tokens}, \n"
                  f"Total tokens: {response.usage.total_tokens}\n"
                  f"Generated response: {response.choices[0].message.content}\n")
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —á–∞—Ç
    # await message.answer(response.choices[0].message.content)
    if response.choices[0].message.content is not None:
        await message.answer(response.choices[0].message.content)
    else:
        log.error("There is no response text to send to the user.")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.")
        await state.clear()
        return
    
    log.info(f"Reply sent to user {user.username}")
    
    await asyncio.sleep(3)  # –¥–∞–¥–∏–º –≤—Ä–µ–º—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –æ—Ç–≤–µ—Ç–∞ –∏ –ø–æ—Ç–æ–º —Å–±—Ä–æ—Å–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    log.debug(f"State reset for user {user.id}")

# -------------------------------------------------------------------------------------------------#
# These handlers are workable but API they use is not free, so we use free Kandinsky API instead   #
# -------------------------------------------------------------------------------------------------#
# @router.message(F.text == "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ üñº")
# async def cmd_generate_image(message: Message, state: FSMContext):
#     await message.answer('–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å')
#     await state.set_state(st.MainStates.await_input_for_gen_text)


# @router.message(st.MainStates.generating_image_state)
# async def send_result(message: Message, state: FSMContext):
#     await state.set_state(st.MainStates.processing_state)
#     await message.answer('–û—Ç–≤–µ—Ç:')
#     response = await gpt_image(message.text)
#     await message.answer_photo(photo=response.data[0].url)
#     await state.clear()
# --------------------------------------------------------------------------------------------------#
